{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the most used words in reviews\n",
    "\n",
    "Our goal with this analysis is to go through all the reviews/comments for all the rooms and identify what Airbnb customers care the most about, when rating the rooms. Our main strategy is a very simple form of Natural Language Processing (NLP), in which we will correlate word frequencies with room ratings. We will also try to apply a simple multi linear regression model to predict the rating based on the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracyRating</th>\n",
       "      <th>allowsChildren</th>\n",
       "      <th>allowsEvents</th>\n",
       "      <th>allowsInfants</th>\n",
       "      <th>allowsPets</th>\n",
       "      <th>allowsSmoking</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>checkinRating</th>\n",
       "      <th>...</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>roomType</th>\n",
       "      <th>serviceFee</th>\n",
       "      <th>totalPrice</th>\n",
       "      <th>url</th>\n",
       "      <th>distToCenter</th>\n",
       "      <th>monthsSinceCreation</th>\n",
       "      <th>daysSinceUpdate</th>\n",
       "      <th>totalAmenities</th>\n",
       "      <th>totalLanguages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21888626</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>56.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>https://www.airbnb.com/rooms/21888626?query=Al...</td>\n",
       "      <td>43.209876</td>\n",
       "      <td>18.833333</td>\n",
       "      <td>544.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23720498</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>63.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>https://www.airbnb.com/rooms/23720498?query=Al...</td>\n",
       "      <td>45.932316</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22981563</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>39.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>https://www.airbnb.com/rooms/22981563?query=Al...</td>\n",
       "      <td>45.391489</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371649</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>29.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>https://www.airbnb.com/rooms/5371649?query=Ale...</td>\n",
       "      <td>41.607718</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18837008</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>67.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>https://www.airbnb.com/rooms/18837008?query=Al...</td>\n",
       "      <td>50.172070</td>\n",
       "      <td>24.966667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracyRating  allowsChildren  allowsEvents  allowsInfants  \\\n",
       "id                                                                      \n",
       "21888626             9.0               1             1              1   \n",
       "23720498            10.0               1             0              1   \n",
       "22981563             9.0               1             0              1   \n",
       "5371649             10.0               1             0              1   \n",
       "18837008             8.0               1             1              1   \n",
       "\n",
       "          allowsPets  allowsSmoking  bathrooms  bedrooms  beds  checkinRating  \\\n",
       "id                                                                              \n",
       "21888626           1              1        1.0       2.0   2.0            9.0   \n",
       "23720498           0              1        2.0       3.0   4.0           10.0   \n",
       "22981563           1              0        1.0       3.0   3.0           10.0   \n",
       "5371649            1              0        2.5       3.0   7.0           10.0   \n",
       "18837008           1              0        1.0       1.0   2.0           10.0   \n",
       "\n",
       "          ...  reviewsCount         roomType  serviceFee  totalPrice  \\\n",
       "id        ...                                                          \n",
       "21888626  ...             7  Entire home/apt        56.0       406.0   \n",
       "23720498  ...             5  Entire home/apt        63.0       463.0   \n",
       "22981563  ...             3  Entire home/apt        39.0       284.0   \n",
       "5371649   ...            31  Entire home/apt        29.0       209.0   \n",
       "18837008  ...             3  Entire home/apt        67.0       492.0   \n",
       "\n",
       "                                                        url  distToCenter  \\\n",
       "id                                                                          \n",
       "21888626  https://www.airbnb.com/rooms/21888626?query=Al...     43.209876   \n",
       "23720498  https://www.airbnb.com/rooms/23720498?query=Al...     45.932316   \n",
       "22981563  https://www.airbnb.com/rooms/22981563?query=Al...     45.391489   \n",
       "5371649   https://www.airbnb.com/rooms/5371649?query=Ale...     41.607718   \n",
       "18837008  https://www.airbnb.com/rooms/18837008?query=Al...     50.172070   \n",
       "\n",
       "          monthsSinceCreation  daysSinceUpdate totalAmenities  totalLanguages  \n",
       "id                                                                             \n",
       "21888626            18.833333            544.0             10               0  \n",
       "23720498            53.333333              3.0             15               5  \n",
       "22981563            16.800000             25.0             17               1  \n",
       "5371649             62.500000              3.0             14               0  \n",
       "18837008            24.966667             11.0             15               4  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#get dataframe from pickle\n",
    "df = pandas.read_pickle(\"Data/final.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The Data\n",
    "\n",
    "Before starting to analyze text data, we first need to go through some text pre-processing techniques. We should note here that this cleaning process could easily go on forever, since there's always an exception to every cleaning step. Therefore, our approach is to follow a minimum viable approach, with clear simple cleaning processes. Our ultimate goal is to get a “bag of words” for each room, ie, a list of relevant words used in each room.\n",
    "\n",
    "# Regular Expressions\n",
    "We proceeded with the following steps, by means of regular expressions:\n",
    "* Merge all comments into one string, by room;\n",
    "* Remove everything from the text data except letters and spaces;\n",
    "* Lowercase every letter;\n",
    "* Remove any word with less than 3 letters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amazing place very nice lady recommend to anywone', 'Lovely home situated in the quiet village of Labrugeria.  Perfect for our needs and wonderful hosts.  A great place to come home to after days out exploring all the lovely sites, beaches and towns of the area.  45 minutes by car to Lisbon and necessary for days out.']\n",
      "amazing place very nice lady recommend anywone lovely home situated the quiet village labrugeria perfect for our needs and wonderful hosts great place come home after days out exploring all the lovely sites beaches and towns the area minutes car lisbon and necessary for days out\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(df.iloc[1,:][\"reviews\"])\n",
    "\n",
    "def mergeAllReviews(row):\n",
    "    merged = \" \".join(list(row))\n",
    "    merged = merged.lower()\n",
    "    merged = re.sub('[^\\\\w ]', ' ', merged) #matches everything but letters and spaces\n",
    "    merged = re.sub('\\\\d', ' ', merged) #matches any digit\n",
    "    merged = re.sub('\\\\b\\\\w{1,2}\\\\b', ' ', merged) #matches any sequence 2 or less letter words. This is because of aposstrophes.\n",
    "    merged = re.sub('\\\\s+', ' ', merged) #matches any sequence of whitespace characters\n",
    "    merged = re.sub('^\\s+|\\s+$', '', merged) #matches whitespaces in the beginning or end of word\n",
    "    \n",
    "    #remove stop words\n",
    "    \n",
    "    return merged\n",
    "\n",
    "df[\"filteredReviews\"] = df[\"reviews\"].apply(lambda x: mergeAllReviews(x))\n",
    "print(df.iloc[1,:][\"filteredReviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords, foreign words and typos\n",
    "Next we went through a slightly more advanced cleaning process. We used the library nltk which has a list of stopwords (very common words that bear no meaning) and a list of “all” english words. We then went through each string of words and converted it to a list of strings, splitting by space. Then we iterated over the list to remove all the stop words and words that don’t exist in the English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazing place very nice lady recommend anywone lovely home situated the quiet village labrugeria perfect for our needs and wonderful hosts great place come home after days out exploring all the lovely sites beaches and towns the area minutes car lisbon and necessary for days out\n",
      "['amazing', 'place', 'nice', 'lady', 'recommend', 'lovely', 'home', 'situated', 'quiet', 'village', 'perfect', 'needs', 'wonderful', 'great', 'place', 'come', 'home', 'days', 'exploring', 'lovely', 'area', 'car', 'necessary', 'days']\n"
     ]
    }
   ],
   "source": [
    "#remove stop words and words that dont exist in english dictionary\n",
    "print(df.iloc[1,:][\"filteredReviews\"])\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('words')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "stopWords = set(stopwords.words('english')) \n",
    "englishWords = set(nltk.corpus.words.words())\n",
    "\n",
    "#tokenize words and remove stop words\n",
    "def tokenizeAndRemoveStopWords(row):\n",
    "    wordTokens = row.split(\" \")\n",
    "    newList=[]\n",
    "    for word in wordTokens:\n",
    "        if (word not in stopWords) and (word in englishWords):\n",
    "            newList.append(word)\n",
    "    return newList\n",
    "\n",
    "df[\"filteredReviews\"] = df[\"filteredReviews\"].apply(lambda x: tokenizeAndRemoveStopWords(x))\n",
    "print(df.iloc[1,:][\"filteredReviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only nouns and adjectives\n",
    "Next, we used nltk once again to categorize each word according to its grammatical category. We decided that the words that port value to our analysis are only nouns and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing', 'place', 'nice', 'lady', 'recommend', 'lovely', 'home', 'situated', 'quiet', 'village', 'perfect', 'needs', 'wonderful', 'great', 'place', 'come', 'home', 'days', 'exploring', 'lovely', 'area', 'car', 'necessary', 'days']\n",
      "['amazing', 'place', 'nice', 'lady', 'home', 'quiet', 'village', 'perfect', 'wonderful', 'great', 'place', 'home', 'days', 'area', 'car', 'necessary', 'days']\n"
     ]
    }
   ],
   "source": [
    "#keep only adjectives (start eith J), non proper nouns (NN and NNS) -> THIS TAKES A LOONNGGG TIME\n",
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "print(df.iloc[1, :][\"filteredReviews\"])\n",
    "\n",
    "#tokenize words and remove stop words\n",
    "def tagAndRemoveWords(row):\n",
    "    newList=[]\n",
    "    tagged = nltk.pos_tag(row)\n",
    "    for entry in tagged :\n",
    "        if entry[1].startswith(\"J\") or entry[1] == \"NN\" or entry[1] == \"NNS\":\n",
    "            newList.append(entry[0])\n",
    "    return newList\n",
    "\n",
    "df[\"filteredReviews\"] = df[\"filteredReviews\"].apply(lambda x: tagAndRemoveWords(x))\n",
    "print(df.iloc[1, :][\"filteredReviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "We again used nltk to stemmatize words, i.e., convert every word to its most elementary stem. For instance, communication stems to commun. However, since these stems are not English words and are difficult to read, we substituted them, for simplicity, by the first word that was stemmatized to the same stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing', 'place', 'nice', 'lady', 'home', 'quiet', 'village', 'perfect', 'wonderful', 'great', 'place', 'home', 'days', 'area', 'car', 'necessary', 'days']\n",
      "['amazing', 'place', 'nice', 'lady', 'home', 'quiet', 'village', 'perfect', 'wonderful', 'great', 'place', 'home', 'days', 'area', 'car', 'necessary', 'days']\n"
     ]
    }
   ],
   "source": [
    "#stemmatize words\n",
    "print(df.iloc[1, :][\"filteredReviews\"])\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "englishWords = set(nltk.corpus.words.words())\n",
    "stemmedWords = {}\n",
    "\n",
    "def stemmatizeWords(row):\n",
    "    stemmer = PorterStemmer()\n",
    "    newList = []\n",
    "    for word in row:\n",
    "        stemmedWord = stemmer.stem(word)\n",
    "        if stemmedWord not in stemmedWords: #this is just so we get an english valid word, and not stemmed\n",
    "            stemmedWords[stemmedWord] = word\n",
    "        newList.append(stemmedWords[stemmedWord])\n",
    "    return newList\n",
    "\n",
    "df[\"filteredReviews\"] = df[\"filteredReviews\"].apply(lambda x: stemmatizeWords(x))\n",
    "df = df[df['filteredReviews'].map(lambda d: len(d)) > 0] #remove all rooms with empty list of words\n",
    "print(df.iloc[1, :][\"filteredReviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatrixTerm and word frequency\n",
    "\n",
    "By using sklearn, we converted the “bag of words” format to a matrix where we have the rooms in the the rows and every word in the columns. The value is the frequency of the word for that room:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abb</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abode</th>\n",
       "      <th>abrasive</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zag</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zig</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21888626</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23720498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22981563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371649</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18837008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abb  ability  able  abnormal  abode  abrasive  abrupt  absence  \\\n",
       "id                                                                         \n",
       "21888626    0        0     0         0      0         0       0        0   \n",
       "23720498    0        0     0         0      0         0       0        0   \n",
       "22981563    0        0     0         0      0         0       0        0   \n",
       "5371649     0        0     1         0      0         0       0        0   \n",
       "18837008    0        0     0         0      0         0       0        0   \n",
       "\n",
       "          absent  absolute  ...  yummy  zag  zenith  zero  zest  zig  zigzag  \\\n",
       "id                          ...                                                \n",
       "21888626       0         0  ...      0    0       0     0     0    0       0   \n",
       "23720498       0         0  ...      0    0       0     0     0    0       0   \n",
       "22981563       0         0  ...      0    0       0     0     0    0       0   \n",
       "5371649        0         0  ...      0    0       0     0     0    0       0   \n",
       "18837008       0         0  ...      0    0       0     0     0    0       0   \n",
       "\n",
       "          zip  zone  zoo  \n",
       "id                        \n",
       "21888626    0     0    0  \n",
       "23720498    0     0    0  \n",
       "22981563    0     0    0  \n",
       "5371649     0     0    0  \n",
       "18837008    0     0    0  \n",
       "\n",
       "[5 rows x 5434 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create document term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform([' '.join(map(str, l)) for l in df['filteredReviews']])\n",
    "matrixTerm = pandas.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "matrixTerm.index = df.index\n",
    "matrixTerm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "#remove rooms with too little words\n",
    "from GeneralFunctions import removeOutliers\n",
    "print(len(matrixTerm))\n",
    "matrixTerm[\"totalWords\"]=matrixTerm.apply(lambda x : x.sum(), axis=1)\n",
    "matrixTerm=removeOutliers(matrixTerm, \"totalWords\", onlyLower=True)\n",
    "print(len(matrixTerm))\n",
    "del matrixTerm[\"totalWords\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words\n",
    "\n",
    "we are going to count, for each word, how many times they appear in a room at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>21888626</th>\n",
       "      <th>23720498</th>\n",
       "      <th>22981563</th>\n",
       "      <th>5371649</th>\n",
       "      <th>18837008</th>\n",
       "      <th>10419816</th>\n",
       "      <th>7354154</th>\n",
       "      <th>21877376</th>\n",
       "      <th>10677809</th>\n",
       "      <th>23156578</th>\n",
       "      <th>...</th>\n",
       "      <th>18092477</th>\n",
       "      <th>17005931</th>\n",
       "      <th>19756855</th>\n",
       "      <th>27901668</th>\n",
       "      <th>15006723</th>\n",
       "      <th>14574388</th>\n",
       "      <th>3167172</th>\n",
       "      <th>11964076</th>\n",
       "      <th>11790067</th>\n",
       "      <th>3671486</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abode</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id        21888626  23720498  22981563  5371649  18837008  10419816  7354154  \\\n",
       "abb              0         0         0        0         0         0        0   \n",
       "ability          0         0         0        0         0         0        0   \n",
       "able             0         0         0        1         0         0        0   \n",
       "abnormal         0         0         0        0         0         0        0   \n",
       "abode            0         0         0        0         0         0        0   \n",
       "\n",
       "id        21877376  10677809  23156578  ...  18092477  17005931  19756855  \\\n",
       "abb              0         0         0  ...         0         0         0   \n",
       "ability          0         0         0  ...         0         0         0   \n",
       "able             0         1         0  ...         0         0         0   \n",
       "abnormal         0         0         0  ...         0         0         0   \n",
       "abode            0         0         0  ...         0         0         0   \n",
       "\n",
       "id        27901668  15006723  14574388  3167172  11964076  11790067  3671486  \n",
       "abb              0         0         0        0         0         0        0  \n",
       "ability          0         0         0        0         0         0        0  \n",
       "able             0         0         0        0         0         0        0  \n",
       "abnormal         0         0         0        0         0         0        0  \n",
       "abode            0         0         0        0         0         0        0  \n",
       "\n",
       "[5 rows x 1115 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we are going to transpose the dataframe\n",
    "matrixTermT = matrixTerm.transpose()\n",
    "matrixTermT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>place</th>\n",
       "      <th>nice</th>\n",
       "      <th>clean</th>\n",
       "      <th>stay</th>\n",
       "      <th>good</th>\n",
       "      <th>host</th>\n",
       "      <th>location</th>\n",
       "      <th>everything</th>\n",
       "      <th>apartment</th>\n",
       "      <th>...</th>\n",
       "      <th>loss</th>\n",
       "      <th>lord</th>\n",
       "      <th>longue</th>\n",
       "      <th>longish</th>\n",
       "      <th>lonesome</th>\n",
       "      <th>loin</th>\n",
       "      <th>logia</th>\n",
       "      <th>loggia</th>\n",
       "      <th>loco</th>\n",
       "      <th>abb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1003</td>\n",
       "      <td>1000</td>\n",
       "      <td>951</td>\n",
       "      <td>943</td>\n",
       "      <td>931</td>\n",
       "      <td>887</td>\n",
       "      <td>887</td>\n",
       "      <td>887</td>\n",
       "      <td>877</td>\n",
       "      <td>850</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 5434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       great  place  nice  clean  stay  good  host  location  everything  \\\n",
       "count   1003   1000   951    943   931   887   887       887         877   \n",
       "\n",
       "       apartment  ...  loss  lord  longue  longish  lonesome  loin  logia  \\\n",
       "count        850  ...     1     1       1        1         1     1      1   \n",
       "\n",
       "       loggia  loco  abb  \n",
       "count       1     1    1  \n",
       "\n",
       "[1 rows x 5434 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will count how many times a word appears in a room at least once\n",
    "wordCount = matrixTermT.astype(bool).sum(axis=1)\n",
    "pandas.DataFrame(wordCount.sort_values(ascending=False), columns = [\"count\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do not want to analyze words that appear too much or too little.\n",
    "rn = matrixTermT.shape[1]\n",
    "commonWords = wordCount[(wordCount/rn > 0.2) & (wordCount/rn < 0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.170882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super</th>\n",
       "      <td>0.163266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitality</th>\n",
       "      <td>0.156517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.153108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welcome</th>\n",
       "      <td>0.151044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0.146134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thoughtful</th>\n",
       "      <td>0.146067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>0.142164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stylish</th>\n",
       "      <td>0.141753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>0.137698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommend</th>\n",
       "      <td>0.136309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.135745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.135555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.134079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special</th>\n",
       "      <td>0.126767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attentive</th>\n",
       "      <td>0.124101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comfortable</th>\n",
       "      <td>0.120728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host</th>\n",
       "      <td>0.118598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>0.118450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip</th>\n",
       "      <td>0.116263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm</th>\n",
       "      <td>0.113756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0.113617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit</th>\n",
       "      <td>0.111720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local</th>\n",
       "      <td>0.110847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.110519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>0.110079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.108557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kind</th>\n",
       "      <td>0.106744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.106086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lots</th>\n",
       "      <td>0.105085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many</th>\n",
       "      <td>0.105084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>0.104895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.104761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>0.103535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everything</th>\n",
       "      <td>0.103392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>0.103175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modern</th>\n",
       "      <td>0.102837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.102071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>0.102056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>0.101877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>0.101625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0.101426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 corr\n",
       "price        0.170882\n",
       "super        0.163266\n",
       "hospitality  0.156517\n",
       "best         0.153108\n",
       "welcome      0.151044\n",
       "home         0.146134\n",
       "thoughtful   0.146067\n",
       "wonderful    0.142164\n",
       "stylish      0.141753\n",
       "excellent    0.137698\n",
       "recommend    0.136309\n",
       "fantastic    0.135745\n",
       "beautiful    0.135555\n",
       "amazing      0.134079\n",
       "special      0.126767\n",
       "attentive    0.124101\n",
       "comfortable  0.120728\n",
       "host         0.118598\n",
       "enjoy        0.118450\n",
       "trip         0.116263\n",
       "warm         0.113756\n",
       "fresh        0.113617\n",
       "visit        0.111720\n",
       "local        0.110847\n",
       "breakfast    0.110519\n",
       "quick        0.110079\n",
       "feel         0.108557\n",
       "kind         0.106744\n",
       "perfect      0.106086\n",
       "lots         0.105085\n",
       "many         0.105084\n",
       "much         0.104895\n",
       "wine         0.104761\n",
       "anyone       0.103535\n",
       "everything   0.103392\n",
       "thank        0.103175\n",
       "modern       0.102837\n",
       "eat          0.102071\n",
       "book         0.102056\n",
       "experience   0.101877\n",
       "full         0.101625\n",
       "helpful      0.101426"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correlation between the words and ratingC\n",
    "\n",
    "df['ratingC'].value_counts().plot(kind='bar')\n",
    "\n",
    "#remove all ratingC<4 because there are just way too few\n",
    "result = pandas.concat([matrixTerm, df[\"ratingC\"]], axis=1, join='inner')\n",
    "\n",
    "newDf = pandas.DataFrame()\n",
    "\n",
    "for word in commonWords.index.values:\n",
    "    newDf.loc[word,\"corr\"] =result[word].corr(result[\"ratingC\"])\n",
    "\n",
    "relevantWords = newDf[(newDf[\"corr\"]>0.1) | (newDf[\"corr\"]<-0.1)].abs().sort_values(by=[\"corr\"], ascending=False)\n",
    "relevantWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.170882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitality</th>\n",
       "      <td>0.156517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thoughtful</th>\n",
       "      <td>0.146067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stylish</th>\n",
       "      <td>0.141753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.135555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special</th>\n",
       "      <td>0.126767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attentive</th>\n",
       "      <td>0.124101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comfortable</th>\n",
       "      <td>0.120728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm</th>\n",
       "      <td>0.113756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0.113617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>0.110519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>0.110079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kind</th>\n",
       "      <td>0.106744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.104761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modern</th>\n",
       "      <td>0.102837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.102071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <td>0.102056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0.101426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 corr\n",
       "price        0.170882\n",
       "hospitality  0.156517\n",
       "thoughtful   0.146067\n",
       "stylish      0.141753\n",
       "beautiful    0.135555\n",
       "special      0.126767\n",
       "attentive    0.124101\n",
       "comfortable  0.120728\n",
       "warm         0.113756\n",
       "fresh        0.113617\n",
       "breakfast    0.110519\n",
       "quick        0.110079\n",
       "kind         0.106744\n",
       "wine         0.104761\n",
       "modern       0.102837\n",
       "eat          0.102071\n",
       "book         0.102056\n",
       "helpful      0.101426"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we now have to manually select words that do not give us any information\n",
    "removeWords=[\"anyone\", \"full\", \"everything\", \"thank\", \"many\", \"much\", \"lots\", \"perfect\", \"feel\", \"make\", \"gem\", \"local\",\n",
    "             \"visit\", \"gorgeous\", \"return\", \"superb\", \"incredible\", \"trip\", \"wish\", \"enjoy\", \"amazing\", \"recommend\",\n",
    "             \"fantastic\", \"excellent\", \"wonderful\", \"home\", \"welcome\", \"best\", \"outstanding\", \"super\", \"stay\", \"felt\", \"great\",\n",
    "            \"sure\", \"anything\", \"hope\", \"plenty\", \"love\", \"apartment\", \"everyone\", \"hesitate\", \"awesome\", \"host\", \"hostess\", \"husband\",\n",
    "            \"way\", \"walk\", \"want\", \"pleasure\", \"explore\", \"real\", \"enough\", \"times\", \"better\", \"travel\", \"spent\", \"moment\", \"fine\",\n",
    "             \"experience\", \"place\"]\n",
    "\n",
    "removeWords = [c for c in removeWords if c in relevantWords.index.values]\n",
    "\n",
    "relevantWords = relevantWords.drop(removeWords)\n",
    "relevantWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-16a9d5705834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#create wordcloud with most relevant words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "#create wordcloud with most relevant words\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "words = \" \".join(relevantWords.index.values)\n",
    "mask = np.array(Image.open(requests.get('http://www.clker.com/cliparts/O/i/x/Y/q/P/yellow-house-hi.png', stream=True).raw))\n",
    "\n",
    "word_cloud = WordCloud(width = 512, height = 512, background_color='white', stopwords=STOPWORDS, mask=mask).generate(words)\n",
    "plt.figure(figsize=(10,8),facecolor = 'white', edgecolor='blue')\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig(\"WordCloudHouse.png\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot \n",
    "We can immediately see that the only word negatively correlated with the rating is price. This probably means that people only talk about price when they are unhappy.\n",
    "It is alto interesting to note that, from the 18 words, the “hospitality” topic is the most common, including “thoughtful, “kind”, “helpful” and “attentive”. So, for an Airbnb host, hospitality and giving away food, namely wine and breakfast, would be an excellent combination.\n",
    "\n",
    "Note, however, that all these words have very poor correlations with the rating, between 0.1 and 0.2. But that is somehow expected due to the nature of text variables, and most prominently word frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for word in relevantWords.index.values:\n",
    "    sns.lmplot(word,y='ratingC',data=result,fit_reg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear regression\n",
    "\n",
    "This gave very bad results, so we decided not to include in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = result.drop(result.columns.difference(relevantWords.index.values),1)\n",
    "Y = result[\"ratingC\"]\n",
    "\n",
    "columns = X.columns.values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                  random_state=1)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train[columns], Y_train)\n",
    "\n",
    "\n",
    "Y_predicted = reg.predict(X_test[columns])\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Y_test, Y_predicted))\n",
    "print('R²: %.2f' % r2_score(Y_test, Y_predicted))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_test, Y_predicted)\n",
    "ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('measured')\n",
    "ax.set_ylabel('predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
